{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd4c5fb-1b44-4698-ac36-8479f74a3d07",
   "metadata": {},
   "source": [
    "# Engergy Forecasting with Deep Learning (Part 1)\n",
    "* In this Tutorial, we will walk through how a data scientist would train a deep learning model for time series forecasting.\n",
    "* In the second notebook (y) we will take the same code and have it in a end-to-end MLOPs pipeline using the Machine Learning Data Management system (MLDM).\n",
    "\n",
    "* The dataset we are using is x\n",
    "* The model we are training is a Temporal Convolutional Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab9931-cd05-40d1-bd03-e3bfa15bdd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from darts.models import TCNModel, RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.metrics import mape, r2_score\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from darts.datasets import AirPassengersDataset, SunspotsDataset, EnergyDataset\n",
    "import warnings\n",
    "from darts.metrics import mape, mse\n",
    "from darts.metrics import mape\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def generate_torch_kwargs():\n",
    "    # run torch models on CPU, and disable progress bars for all model stages except training.\n",
    "    return {\n",
    "        \"pl_trainer_kwargs\": {\n",
    "            \"accelerator\": \"cpu\",\n",
    "            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True)],\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700fd93-399c-4ae7-b02c-1582a6ec8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "\n",
    "dataset_url='data/energy_dataset.csv'\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "df3 = pd.read_csv(dataset_url, parse_dates=['time'])\n",
    "df3.set_index('time', inplace=True)\n",
    "\n",
    "# Convert a specific column into a TimeSeries object for demonstration\n",
    "# Example, let's use 'generation fossil gas'\n",
    "time_series_gas = TimeSeries.from_series(df3['generation fossil gas'])\n",
    "\n",
    "# Display the first few rows of the time series to confirm successful loading\n",
    "print(time_series_gas.pd_dataframe().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c84e8c-3222-4a51-87a7-a20f47b6ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_day_avg = (\n",
    "    df3.groupby(df3.index.astype(str).str.split(\" \").str[0]).mean().reset_index()\n",
    ")\n",
    "series_en = fill_missing_values(\n",
    "    TimeSeries.from_dataframe(\n",
    "        df3_day_avg, \"time\", [\"generation hydro run-of-river and poundage\"]\n",
    "    ),\n",
    "    \"auto\",\n",
    ")\n",
    "\n",
    "# create train and test splits\n",
    "train_en, val_en = series_en.split_after(pd.Timestamp(\"20170901\"))\n",
    "\n",
    "# scale the data\n",
    "scaler_en = Scaler()\n",
    "train_en_transformed = scaler_en.fit_transform(train_en)\n",
    "val_en_transformed = scaler_en.transform(val_en)\n",
    "series_en_transformed = scaler_en.transform(series_en)\n",
    "\n",
    "# add the day as a covariate (scaling not required as one-hot-encoded)\n",
    "day_series = datetime_attribute_timeseries(\n",
    "    series_en_transformed, attribute=\"day\", one_hot=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "train_en_transformed.plot(label=\"train\")\n",
    "val_en_transformed.plot(label=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a218c0-f9aa-445c-9139-038021f0abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformed training and validation series to files using pickle\n",
    "import pickle\n",
    "\n",
    "with open('cache/train_en_transformed.pkl', 'wb') as f:\n",
    "    pickle.dump(train_en_transformed, f)\n",
    "with open('cache/val_en_transformed.pkl', 'wb') as f:\n",
    "    pickle.dump(val_en_transformed, f)\n",
    "with open('cache/day_series.pkl', 'wb') as f:\n",
    "    pickle.dump(day_series, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f56b93-061e-4417-85d0-73d3460c488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformed training and validation series from files using pickle\n",
    "with open('cache/train_en_transformed.pkl', 'rb') as f:\n",
    "    train_en_transformed = pickle.load(f)\n",
    "with open('cache/val_en_transformed.pkl', 'rb') as f:\n",
    "    val_en_transformed = pickle.load(f)\n",
    "with open('cache/day_series.pkl', 'rb') as f:\n",
    "    day_series = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02110e61-a527-473f-b545-1e2d35f5e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to see what loading the transformed training and validation series from files\n",
    "train_en_transformed2 = TimeSeries.load('train_en_transformed.pkl')\n",
    "val_en_transformed2 = TimeSeries.load('val_en_transformed.pkl')\n",
    "# And in the script where you load the datasets\n",
    "day_series2 = TimeSeries.load('day_series.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37818e-4905-44b3-bdb8-3735956db6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TCN_energy\"\n",
    "model_en = TCNModel(\n",
    "    input_chunk_length=365,\n",
    "    output_chunk_length=7,\n",
    "    n_epochs=50,\n",
    "    dropout=0.2,\n",
    "    dilation_base=2,\n",
    "    weight_norm=True,\n",
    "    kernel_size=5,\n",
    "    num_filters=8,\n",
    "    nr_epochs_val_period=1,\n",
    "    random_state=0,\n",
    "    save_checkpoints=True,\n",
    "    model_name=model_name,\n",
    "    force_reset=True,\n",
    "    **generate_torch_kwargs()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60ba26-7422-432d-8a71-f5e64382fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en.load_weights(\"TCN_model.pt\")\n",
    "model_en.n_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25ce3c-3bba-4af4-903f-7b3d4d4b4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en.fit(\n",
    "    series=train_en_transformed,\n",
    "    past_covariates=day_series,\n",
    "    val_series=val_en_transformed,\n",
    "    val_past_covariates=day_series,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36a15c-12f9-4277-8fc1-1d1e42329e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training is done, lets save the model\n",
    "model_en.save(\"models/TCN_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eecff9c-0cec-43c7-8c4d-edb47f0dbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is code to show how we can load a model from weights\n",
    "model_name = \"TCN_energy\"\n",
    "model_en = TCNModel(\n",
    "    input_chunk_length=365,\n",
    "    output_chunk_length=7,\n",
    "    n_epochs=50,\n",
    "    dropout=0.2,\n",
    "    dilation_base=2,\n",
    "    weight_norm=True,\n",
    "    kernel_size=5,\n",
    "    num_filters=8,\n",
    "    nr_epochs_val_period=1,\n",
    "    random_state=0,\n",
    "    save_checkpoints=True,\n",
    "    model_name=model_name,\n",
    "    force_reset=True,\n",
    "    **generate_torch_kwargs()\n",
    ")\n",
    "model_en.load_weights(\"TCN_model.pt\")\n",
    "# If we want to finetune with less than the pretraining epochs, we need to change the n_epochs attribute\n",
    "model_en.n_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b878f68-0045-4242-a7a9-e56bb7fbde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest validation\n",
    "backtest_en = model_en.historical_forecasts(\n",
    "    series=series_en_transformed,\n",
    "    past_covariates=day_series,\n",
    "    start=val_en_transformed.start_time(),\n",
    "    forecast_horizon=7,\n",
    "    stride=7,\n",
    "    last_points_only=False,\n",
    "    retrain=False,\n",
    "    verbose=True,\n",
    ")\n",
    "backtest_en = concatenate(backtest_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c1926-f286-4aec-aa19-642cc1f67430",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "val_en_transformed.plot(label=\"actual\")\n",
    "backtest_en.plot(label=\"backtest (H=7)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43222375-7e60-4738-9047-28cfce320808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the model is loaded (you should have executed this part already)\n",
    "# model_en = TCNModel.load_from_checkpoint(model_name=model_name, best=True)\n",
    "\n",
    "# Forecast on the training set\n",
    "backtest_train = model_en.historical_forecasts(\n",
    "    series=train_en_transformed,\n",
    "    past_covariates=day_series,\n",
    "    forecast_horizon=7,\n",
    "    retrain=False,\n",
    "    verbose=True,\n",
    "    overlap_end=False  # Avoid overlapping with validation period\n",
    ")\n",
    "\n",
    "# Forecast on the validation set\n",
    "backtest_val = model_en.historical_forecasts(\n",
    "    series=val_en_transformed,\n",
    "    past_covariates=day_series,\n",
    "    forecast_horizon=7,\n",
    "    retrain=False,\n",
    "    verbose=True,\n",
    "    overlap_end=False\n",
    ")\n",
    "\n",
    "# Compute RMSE for the training and validation sets\n",
    "rmse_train = round(rmse(train_en_transformed, backtest_train),2)\n",
    "rmse_val = round(rmse(val_en_transformed, backtest_val),2)\n",
    "\n",
    "print(f\"RMSE on Training Set: {rmse_train}\")\n",
    "print(f\"RMSE on Validation Set: {rmse_val}\")\n",
    "\n",
    "# Plotting the actual vs. forecasted values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training set plot\n",
    "plt.subplot(1, 2, 1)\n",
    "train_en_transformed.plot(label=\"Actual - Train\")\n",
    "backtest_train.plot(label=\"Forecast - Train\")\n",
    "plt.title('Training Set Forecasts '+f'MAPE: {rmse_train}')\n",
    "plt.legend()\n",
    "\n",
    "# Validation set plot\n",
    "plt.subplot(1, 2, 2)\n",
    "val_en_transformed.plot(label=\"Actual - Validation\")\n",
    "backtest_val.plot(label=\"Forecast - Validation\")\n",
    "plt.title('Validation Set Forecasts '+f'MAPE: {rmse_val}')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
